---
layout: post
title:  "[深度学习] 1 神经网络"
date:   2016-08-14 23:34:41
category: "深度学习"
---

如今深度学习的研究越来越受到国内外学术界和商业界的青睐，本专题旨在从原理到应用对深度学习进行剖析讲解。欢迎大家对本人拙见给予指正。

# 1. 简介

多层感知网络，是一种人工神经网络结构，是非参数估计器。
> 1 - 用途：分类、回归
> 2 - 训练算法：后向传播算法

## 1.1理解人脑
信息处理系统具有三个层面，称为***分析层面***：
> 1 - 计算理论：例如【排序】，对给定的元素集合排序；
> 2 - 表示和算法：例如【排序】，整数、快速排序；
> 3 - 硬件实现：例如【排序】，可执行代码。

    人脑是学习或模式识别（计算理论）的一种硬件实现，当我们研究人工神经网络时，我们处于表示和算法层面。

## 1.2 并行处理
目前有两种并行处理范性： 
> 1  - SIMD（单指令多数据）：所有的处理器执行相同的命令，在数据的不同部分执行；
> 2  - MIMD（多指令多数据）：不同的处理器可以在不同的数据上执行不同的指令。
    
    人工神经网络是一种我们可以使用当前技术构建的，利用并行硬件的方法。

# 2. 感知器
感知器是最基本处理单元，它具有输入、连接权重和输出，其中：
> 1 - 输入：可能来自环境或者其他感知器的输出
> 2 - 连接权重：是与每一个输入相关联的值
> 3 - 输出：是输入与权重的函数值

# 3. 训练感知器
感知器定义了一个超平面，而神经网络感知器只不过是实现超平面的一种方法。
给定数据样本，可以 ***离线*** 地计算权重，当他们代入时，感知器可以用来计算输出值。

      在训练神经网络时，如果未提供全部样本，而是逐个提供实例，则通常使用在线学习；
    并且在每个实例到达后更新网络参数，让网络缓慢地及时调整。

> 如果误差函数是可微的，则可以使用梯度下降。

# 4. 多层感知器
具有单层权重的感知器只能近似输入的线性函数，不能解决像XOR这样的问题，这些问题的判别式是非线性的。类似的，这种感知器也不能用于非线性回归。
对于输入和输出层之间存在中间层或隐藏层的前馈网络，就不存在这种局限性。如果用于分类，这种**多层感知器**（MLP）可以实现非线性判别式，而如果用于回归，可以近似输入的非线性函数。

    如果隐藏层单元的输出是线性的，则隐藏层就没有用；线性组合的线性组合还是一种线性组合。

# 5. 后向传播算法
训练多层感知器与训练一个感知器一样。唯一的区别是现在的输出是输入的非线性函数，这多亏了隐藏单元中的非线性偏移函数。

# 6. 训练过程
> 1 - 改善收敛性
> 2 - 过分训练
> 3 - 构造网络

# 7. 深度学习
具有一个隐藏层的MLP的能力有限，而使用具有多个隐藏层的MLP可以学习输入的更复杂的函数，这就是**深度神经网络**背后的思想。
> 在深度学习中，基本思想是以最小的人力学习递增的抽象的特征层。
